{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for testing performance of intent classification in Watson Conversation Service\n",
    "[Watson Developer Cloud](https://www.ibm.com/watsondevelopercloud) is a platform of cognitive services that leverage machine learning techniques to help partners and clients solve a variety business problems. Furthermore, several of the WDC services fall under the **supervised learning** suite of machine learning algorithms, that is, algorithms that learn by example. This begs the questions: \"How many examples should we provide?\" and \"When is my solution ready for prime time?\"\n",
    "\n",
    "It is critical to understand that training a machine learning solution is an iterative process where it is important to continually improve the solution by providing new examples and measuring the performance of the trained solution. In this notebook, we show how you can compute important Machine Learning metrics (accuracy, precision, recall, confusion_matrix) to judge the performance of your Watson Conversation service solution. For more details on these various metrics, please consult the **[Is Your Chatbot Ready for Prime-Time?](https://developer.ibm.com/dwblog/2016/chatbot-cognitive-performance-metrics-accuracy-precision-recall-confusion-matrix/)** blog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The notebook assumes you have already created a [Watson Conversation Service](https://www.ibm.com/watson/developercloud/conversation.html) instance and trained it based on a number of intents. </br>\n",
    "<br> To leverage this notebook, you need to provide the following information</br>\n",
    "* Credentials for your Watson Conversation instance (username and password)\n",
    "* Workspace id for your conversation \n",
    "* csv file with your text utterances and corresponding intent labels\n",
    "* results csv file to write the results to\n",
    "* csv file to write confusion matrix results to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only run this cell if you don't have pandas_ml or watson_developer_cloud installed\n",
    "!pip install pandas_ml\n",
    "# You can specify the latest verion of watson_developer_cloud (1.0.0 as of November 20, 2017)\n",
    "!pip install -I watson-developer-cloud==1.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import utilities\n",
    "import json\n",
    "import sys\n",
    "import codecs\n",
    "import unicodecsv as csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ml\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from watson_developer_cloud import ConversationV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the path to the parms file which includes credentials to access your Conversation service as well as the input\n",
    "test csv file and the output csv files to write the output results and confusion matrix to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample parms file data\n",
    "#{\n",
    "#\t\"url\": \"https://gateway.watsonplatform.net/conversation/api\",\n",
    "#\t\"user\":\"YOUR_WCS_USERNAME\",\n",
    "#\t\"password\": \"YOUR_WCS_PASSWORD\",\n",
    "#\t\"workspace_id\":\"YOUR_WCS_WORKSPACE_ID\",\n",
    "#\t\"test_csv_file\": \"COMPLETE_PATH_TO_YOUR_TEST_CSV_FILE\",\n",
    "#\t\"results_csv_file\": \"COMPLETE PATH TO RESULTS FILE (any file you can write to)\",\n",
    "#\t\"confmatrix_csv_file\": \"COMPLETE PATH TO CONFUSION MATRIX FILE (any file you can write to)\"\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Provide complete path to the file which includes all required parms\n",
    "# A sample parms file is included (example_parms.json)\n",
    "convParmsFile = 'COMPLETE PATH TO YOUR PARM FILE'\n",
    "parms = ''\n",
    "with open(convParmsFile) as parmFile:\n",
    "    parms = json.load(parmFile)\n",
    "\n",
    "url=parms['url']\n",
    "user=parms['user']\n",
    "password=parms['password']\n",
    "workspace_id=parms['workspace_id']\n",
    "test_csv_file=parms['test_csv_file']\n",
    "results_csv_file=parms['results_csv_file']\n",
    "confmatrix_csv_file=parms['confmatrix_csv_file']\n",
    "\n",
    "# Create an object for your Conversation instance\n",
    "# Make sure to update the version to match your WCS workspace\n",
    "conversation = ConversationV1(\n",
    "  username=user,\n",
    "  password=password,\n",
    "  version='2017-05-26')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define useful methods to classify using trained Watson Conversation service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a text string and a pointer to Conversation instance and workspaceID, get back Conversation response\n",
    "def getConversationResponse(conv_instance,workspaceID,string):\n",
    "    context={}\n",
    "    # remove newlines from input text as that causes WCS to return an error\n",
    "    string = string.replace(\"\\n\",\"\")\n",
    "    response = conv_instance.message(\n",
    "        workspace_id=workspaceID, \n",
    "        input={'text':string},\n",
    "        context=context)\n",
    "    classes=response\n",
    "    return classes\n",
    "\n",
    "# Process multiple text utterances (provided via csv file) in batch. Effectively, read the csv file and for each text\n",
    "# utterance, get NLC response. Aggregate and return results.\n",
    "def batchConversation(conv_instance,workspaceID,csvfile):\n",
    "    test_classes=[]\n",
    "    convpredict_classes=[]\n",
    "    convpredict_confidence=[]\n",
    "    text=[]\n",
    "    i=0\n",
    "    print ('reading csv file: ', csvfile)\n",
    "    with open(csvfile,\"rb\") as csvfile:\n",
    "        # For better handling of utf8 encoded text\n",
    "        csvReader = csv.reader(csvfile, encoding=\"utf-8-sig\")\n",
    "        for row in csvReader:\n",
    "            # Assume input text is 2 column csv file, first column is text\n",
    "            # and second column is the label/class/intent\n",
    "            # Sometimes, the text string includes commas which may split\n",
    "            # the text across multiple colmns. The following code handles that.\n",
    "            if len(row) > 2:\n",
    "                qelements = row[0:len(row)-1]\n",
    "                utterance = \",\".join(qelements)\n",
    "                test_classes.append(row[len(row)-1])\n",
    "            else:\n",
    "                utterance = row[0]\n",
    "                test_classes.append(row[1])\n",
    "            utterance = utterance.replace('\\r', ' ')\n",
    "            print ('i: ', i, ' testing row: ', utterance)\n",
    "          \n",
    "            conv_response = getConversationResponse(conv_instance,workspaceID,utterance)\n",
    "            if conv_response['intents']: \n",
    "                convpredict_classes.append(conv_response['intents'][0]['intent'])\n",
    "                convpredict_confidence.append(conv_response['intents'][0]['confidence'])\n",
    "            else:\n",
    "                convpredict_classes.append('')\n",
    "                convpredict_confidence.append(0)\n",
    "            text.append(utterance)\n",
    "            i = i+1\n",
    "            if(i%250 == 0):\n",
    "                print(\"\")\n",
    "                print('Processed ', i, ' records')\n",
    "            if(i%10 == 0):\n",
    "                sys.stdout.write('.'),\n",
    "        print(\"\")\n",
    "        print ('Finished processing ', i, ' records')\n",
    "    return test_classes, convpredict_classes, convpredict_confidence, text\n",
    "\n",
    "# Plot confusion matrix as an image\n",
    "def plot_conf_matrix(conf_matrix):\n",
    "    plt.figure()\n",
    "    plt.imshow(conf_matrix)\n",
    "    plt.show()\n",
    "\n",
    "# Print confusion matrix to a csv file\n",
    "def confmatrix2csv(conf_matrix,labels,csvfile):\n",
    "    with open(csvfile, 'wb') as csvfile:\n",
    "        csvWriter = csv.writer(csvfile)\n",
    "        row=list(labels)\n",
    "        row.insert(0,\"\")\n",
    "        csvWriter.writerow(row)\n",
    "        for i in range(conf_matrix.shape[0]):\n",
    "            row=list(conf_matrix[i])\n",
    "            row.insert(0,labels[i])\n",
    "            csvWriter.writerow(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an optional step to quickly test response from NLC for a given utterance\n",
    "#testQ='I have a billing question'\n",
    "#results = getConversationResponse(conversation,workspace_id,testQ)\n",
    "#print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Conversation on the specified csv file and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classes,convpredict_classes,convpredict_conf,text=batchConversation(conversation,workspace_id,test_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print results to csv file including original text, the correct label, \n",
    "# the predicted label and the confidence reported by Conversation.\n",
    "csvfileOut=results_csv_file\n",
    "csvWriter = codecs.open(csvfileOut, 'w', encoding=\"utf-8-sig\")\n",
    "\n",
    "outrow=['text','true class','Conversation Predicted class','Confidence']\n",
    "csvWriter.write(\"text\"+\",\"+\"true class\"+\",\"+\"Conversation Predicted class\"+\",\"+\"Confidence\")\n",
    "csvWriter.write(\"\\n\")\n",
    "\n",
    "for i in range(len(text)):\n",
    "    t = text[i]\n",
    "    txt = text[i]\n",
    "    if txt[:1] != '\"' or txt.strip()[-1] != '\"':\n",
    "        txt = \"\\\"\" + txt + \"\\\"\"\n",
    "    csvWriter.write(txt+\",\"+test_classes[i]+\",\"+convpredict_classes[i]+\",\"+str(convpredict_conf[i]))\n",
    "    csvWriter.write(\"\\n\")\n",
    "csvWriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "labels=list(set(test_classes))\n",
    "conv_confusion_matrix = confusion_matrix(test_classes, convpredict_classes, labels)\n",
    "convConfMatrix = ConfusionMatrix(test_classes, convpredict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out confusion matrix with labels to csv file\n",
    "confmatrix2csv(conv_confusion_matrix,labels,confmatrix_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "convConfMatrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute accuracy of classification\n",
    "acc=accuracy_score(test_classes, convpredict_classes)\n",
    "print ('Classification Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print precision, recall and f1-scores for the different classes\n",
    "print(classification_report(test_classes, convpredict_classes, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optional if you would like each of these metrics separately\n",
    "#[precision,recall,fscore,support]=precision_recall_fscore_support(test_classes, convpredict_classes, labels=labels)\n",
    "#print ('precision: ', precision)\n",
    "#print ('recall: ', recall)\n",
    "#print ('f1 score: ', fscore)\n",
    "#print ('support: ', support)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
