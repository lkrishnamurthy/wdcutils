{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing performance of Visaul Recognition Custom Classifiers\n",
    "[Watson Developer Cloud](https://www.ibm.com/watsondevelopercloud) is a platform of cognitive services that leverage machine learning techniques to help partners and clients solve a variety of business problems. Furthermore, several of the WDC services fall under the **supervised learning** suite of machine learning algorithms, that is, algorithms that learn by example. This begs the questions: \"How many examples should we provide?\" and \"When is my solution ready for prime time?\"\n",
    "\n",
    "It is critical to understand that training a machine learning solution is an iterative process where it is important to continually improve the solution by providing new examples and measuring the performance of the trained solution. In this notebook, we show how you can compute important Machine Learning metrics (accuracy, precision, recall, confusion_matrix) to judge the performance of your solution. For more details on these various metrics, please consult the **[Is Your Chatbot Ready for Prime-Time?](https://developer.ibm.com/dwblog/2016/chatbot-cognitive-performance-metrics-accuracy-precision-recall-confusion-matrix/)** blog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The notebook assumes you have already created a Watson [Visual Recognition](https://www.ibm.com/watson/developercloud/visual-recognition.html) instance and trained [custom classifiers](https://www.ibm.com/watson/developercloud/doc/visual-recognition/tutorial-custom-classifier.html). </br>\n",
    "<br> To leverage this notebook, you need to provide the following information</br>\n",
    "* Credentials for your Visual Recognition instance (apikey)\n",
    "* id for your trained classifier (this is returned when you train your Visual Recognition custom classifier)\n",
    "* csv file with your test images (paths to images on your local disk) and corresponding class labels\n",
    "* results csv file to write the results to (true vs. predicted class labels)\n",
    "* csv file to write confusion matrix to\n",
    "\n",
    "Note that the input test csv file should have a header with the fields **image** and **class**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only run this the first time if pandas_ml is not installed on your machine\n",
    "!pip install pandas_ml\n",
    "# latest version of watson_developer_cloud (1.0.0) as of November 20, 2017\n",
    "!pip install -I watson_developer_cloud==1.0.0\n",
    "# previous version of watson_developer_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import utilities\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ml\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from watson_developer_cloud import VisualRecognitionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the path to the parms file which includes credentials to access your VR service as well as the input\n",
    "test csv file and the output csv files to write the output results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample parms file data\n",
    "#{\n",
    "#\t\"url\": \"https://gateway-a.watsonplatform.net/visual-recognition/api\",\n",
    "#\t\"apikey\":\"YOUR_VISUAL_RECOGNITION_APIKEY\",\n",
    "#\t\"vr_id\":\"YOUR_VISUAL_RECOGNITION_CUSTOM_CLASSIFIER_ID\",\n",
    "#\t\"test_csv_file\": \"COMPLETE_PATH_TO_YOUR_TEST_CSV_FILE\",\n",
    "#\t\"results_csv_file\": \"COMPLETE PATH TO RESULTS FILE (any file you can write to)\",\n",
    "#\t\"confmatrix_csv_file\": \"COMPLETE PATH TO CONFUSION MATRIX FILE (any file you can write to)\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Provide complete path to the file which includes all required parms\n",
    "# A sample parms file is included (example_VR_parms.json)\n",
    "vrParmsFile = 'COMPLETE PATH TO YOUR PARMS FILE'\n",
    "parms = ''\n",
    "with open(vrParmsFile) as parmFile:\n",
    "    parms = json.load(parmFile)\n",
    "\n",
    "url=parms['url']\n",
    "apikey=parms['apikey']\n",
    "vr_id=parms['vr_id']\n",
    "test_csv_file=parms['test_csv_file']\n",
    "results_csv_file=parms['results_csv_file']\n",
    "confmatrix_csv_file=parms['confmatrix_csv_file']\n",
    "\n",
    "json.dumps(parms)\n",
    "\n",
    "# Create an object for your Visual Recognition instance\n",
    "visual_recognition = VisualRecognitionV3('2016-05-20', api_key=apikey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define useful methods to classify using custom VR classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given an image and a pointer to VR instance and classifierID, get back VR response\n",
    "def getVRresponse(vr_instance,classifierID,image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        parameters = json.dumps({'threshold':0.01, 'classifier_ids': [classifierID]})\n",
    "       #parameters = json.dumps({'threshold':0.01, 'classifier_ids': ['travel_1977348895','travel_2076475268','default']}) \n",
    "        image_results = vr_instance.classify(images_file=image_file,\n",
    "                                             parameters = parameters)\n",
    "        # For our purposes, we assume each call is to classify one image\n",
    "        # Although the Visual Recognition classify endpoint accepts as input\n",
    "        # a .zip file, we need each image to be labeled with the correct class\n",
    "        classList = []\n",
    "        for classifier in image_results['images'][0]['classifiers']:\n",
    "            if classifier['classifier_id'] == vr_id:\n",
    "                classList = classifier['classes']\n",
    "                break\n",
    "        # Sort the returned classes by score\n",
    "        #print(\"classList: \", classList)\n",
    "        sorted_classList = sorted(classList, key=lambda k: k.get('score', 0), reverse=True)\n",
    "        #print(\"sortedList: \", sorted_classList)\n",
    "    return sorted_classList\n",
    "\n",
    "# Process multiple images (provided via csv file) in batch. Effectively, read the csv file and for each image\n",
    "# utterance, get VR response. Aggregate and return results.\n",
    "def batchVR(vr_instance,classifierID,csvfile):\n",
    "    test_classes=[]\n",
    "    vr_predict_classes=[]\n",
    "    vr_predict_confidence=[]\n",
    "    images=[]\n",
    "    i=0\n",
    "    with open(csvfile, 'r') as csvfile:\n",
    "        csvReader=csv.DictReader(csvfile)\n",
    "        for row in csvReader:\n",
    "            test_classes.append(row['class'])\n",
    "            vr_response = getVRresponse(vr_instance,classifierID,row['image'])\n",
    "            vr_predict_classes.append(vr_response[0]['class'])\n",
    "            vr_predict_confidence.append(vr_response[0]['score'])\n",
    "            images.append(row['image'])\n",
    "            i = i+1\n",
    "            if(i%250 == 0):\n",
    "                print(\"\")\n",
    "                print(\"Processed \", i, \" records\")\n",
    "            if(i%10 == 0):\n",
    "                sys.stdout.write('.')\n",
    "        print(\"\")\n",
    "        print(\"Finished processing \", i, \" records\")\n",
    "    return test_classes, vr_predict_classes, vr_predict_confidence, images\n",
    "\n",
    "# Plot confusion matrix as an image\n",
    "def plot_conf_matrix(conf_matrix):\n",
    "    plt.figure()\n",
    "    plt.imshow(conf_matrix)\n",
    "    plt.show()\n",
    "\n",
    "# Print confusion matrix to a csv file\n",
    "def confmatrix2csv(conf_matrix,labels,csvfile):\n",
    "    with open(csvfile, 'w') as csvfile:\n",
    "        csvWriter = csv.writer(csvfile)\n",
    "        row=list(labels)\n",
    "        row.insert(0,\"\")\n",
    "        csvWriter.writerow(row)\n",
    "        for i in range(conf_matrix.shape[0]):\n",
    "            row=list(conf_matrix[i])\n",
    "            row.insert(0,labels[i])\n",
    "            csvWriter.writerow(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of all custom classifiers in your visual recognition service\n",
    "#print(json.dumps(visual_recognition.list_classifiers(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an optional step to quickly test response from Visual Recognition for a given image\n",
    "##testImage='COMPLETE PATH TO YOUR TEST IMAGE'\n",
    "##classifierList = \"'\" + vr_id + \"'\" + \",\" + \"'\" + \"default\" + \"'\"\n",
    "##results = getVRresponse(visual_recognition,vr_id,testImage)\n",
    "\n",
    "##print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Visual Recognition on the specified csv file and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes,vr_predict_classes,vr_predict_conf,images=batchVR(visual_recognition,vr_id,test_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print results to csv file including original text, the correct label, \n",
    "# the predicted label and the confidence reported by NLC.\n",
    "csvfileOut=results_csv_file\n",
    "with open(csvfileOut, 'w') as csvOut:\n",
    "    outrow=['image','true class','VR Predicted class','Confidence']\n",
    "    csvWriter = csv.writer(csvOut,dialect='excel')\n",
    "    csvWriter.writerow(outrow)\n",
    "    for i in range(len(images)):\n",
    "        outrow=[images[i],test_classes[i],vr_predict_classes[i],str(vr_predict_conf[i])]\n",
    "        csvWriter.writerow(outrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "labels=list(set(test_classes))\n",
    "vr_confusion_matrix = confusion_matrix(test_classes, vr_predict_classes, labels)\n",
    "vrConfMatrix = ConfusionMatrix(test_classes, vr_predict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out confusion matrix with labels to csv file\n",
    "confmatrix2csv(vr_confusion_matrix,labels,confmatrix_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "vrConfMatrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy of classification\n",
    "acc=accuracy_score(test_classes, vr_predict_classes)\n",
    "print('Classification Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print precision, recall and f1-scores for the different classes\n",
    "print(classification_report(test_classes, vr_predict_classes, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optional if you would like each of these metrics separately\n",
    "#[precision,recall,fscore,support]=precision_recall_fscore_support(test_classes, vr_predict_classes, labels=labels)\n",
    "#print(\"precision: \", precision)\n",
    "#print(\"recall: \", recall)\n",
    "#print(\"f1 score: \", fscore)\n",
    "#print(\"support: \", support)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
